{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "data_train = pd.read_csv('train_2008.csv')\n",
    "dft = pd.read_csv('test_2012.csv')\n",
    "print(dft.shape)\n",
    "#remove = ['id', 'HRMONTH', 'HRYEAR4']\n",
    "#dft = dft.drop(remove, axis=1)\n",
    "#data_train = data_train.drop(remove, axis=1)\n",
    "y = data_train['target']\n",
    "df = data_train.drop(['target'], axis = 1)\n",
    "\n",
    "test = pd.concat([df['GESTFIPS'], y], axis=1)\n",
    "test2 = test[test['target'] != 0]\n",
    "test2 = test2.drop(columns=['target'])\n",
    "test = test.drop(columns=['target'])\n",
    "tes2 = test2['GESTFIPS'].value_counts()\n",
    "tes1 = test['GESTFIPS'].value_counts()\n",
    "result = (tes2 / tes1)\n",
    "for i in range(60):\n",
    "    if i in result.keys():\n",
    "        df.loc[df['GESTFIPS'] == i, 'GESTFIPS'] = result[i] ** 2\n",
    "        dft.loc[dft['GESTFIPS'] == i, 'GESTFIPS'] = result[i] ** 2\n",
    "    else:\n",
    "        df.loc[df['GESTFIPS'] == i, 'GESTFIPS'] = result.mean() ** 2\n",
    "        dft.loc[dft['GESTFIPS'] == i, 'GESTFIPS'] = result.mean() ** 2\n",
    "        \n",
    "\n",
    "test = pd.concat([df['PEEDUCA'], y], axis=1)\n",
    "test2 = test[test['target'] != 0]\n",
    "test2 = test2.drop(columns=['target'])\n",
    "test = test.drop(columns=['target'])\n",
    "tes2 = test2['PEEDUCA'].value_counts()\n",
    "tes1 = test['PEEDUCA'].value_counts()\n",
    "result = (tes2 / tes1)\n",
    "\n",
    "for i in range(60):\n",
    "    if i in result.keys():\n",
    "        df.loc[df['PEEDUCA'] == i, 'PEEDUCA'] = result[i] ** 2\n",
    "        dft.loc[dft['PEEDUCA'] == i, 'PEEDUCA'] = result[i] ** 2\n",
    "    else:\n",
    "        df.loc[df['PEEDUCA'] == i, 'PEEDUCA'] = result.mean() ** 2\n",
    "        dft.loc[dft['PEEDUCA'] == i, 'PEEDUCA'] = result.mean() ** 2 \n",
    "\n",
    "#df = df.append(dft, ignore_index = True)\n",
    "scaler = StandardScaler()\n",
    "df[df.columns[:].tolist()] = scaler.fit_transform(df[df.columns[:].tolist()])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dft[dft.columns[:].tolist()] = scaler.fit_transform(dft[dft.columns[:].tolist()])\n",
    "\n",
    "#X = df[df.columns[:].tolist()]\n",
    "#y_train = y\n",
    "#X_train = X.head(64667)\n",
    "#X_test = X.tail(16000)\n",
    "\n",
    "X_train = df[df.columns[:].tolist()]\n",
    "y_train = y\n",
    "X_test = dft[dft.columns[:].tolist()]\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train.values, y_train.values, test_size=0.2, random_state=123)\n",
    "\n",
    "# Create model here given constraints in the problem\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.30))\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(X_train1, y_train1, batch_size=170, nb_epoch=20)\n",
    "model.summary()\n",
    "pred = model.predict(X_test1)\n",
    "pred_test = model.predict(X_test)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "\n",
    "n_estimators_optimal = -1\n",
    "\n",
    "data_train = pd.read_csv('train_2008.csv')\n",
    "dft = pd.read_csv('test_2012.csv')\n",
    "#remove = ['id', 'HRMONTH', 'HRYEAR4']\n",
    "#dft = dft.drop(remove, axis=1)\n",
    "#data_train = data_train.drop(remove, axis=1)\n",
    "y = data_train['target']\n",
    "df = data_train.drop(['target'], axis = 1)\n",
    "\n",
    "#for c in to_remove:\n",
    "#    cols.remove(c)\n",
    "\n",
    "cols = [\"HUFINAL\", \"HETENURE\", \"HRHTYPE\", \"GEREG\", \"GESTCEN\", \"GTCBSAST\", \"GTCSA\", \"PERRP\", \"GESTFIPS\", \"PEEDUCA\",\n",
    "        'PEMARITL', 'PTDTRACE', 'PRDTHSP', 'PENATVTY', 'PEMNTVTY', 'PEFNTVTY', 'PUSLFPRX', 'PEHRRSN2', 'PRCHLD', \n",
    "        'PEIO1COW', 'PUIO1MFG', 'PRDTCOW1', 'PRDTIND1', 'PRDTOCC1', 'HEHOUSUT']\n",
    "\n",
    "for col in cols:\n",
    "    test = pd.concat([df[col], y], axis=1)\n",
    "    test2 = test[test['target'] != 0]\n",
    "    test2 = test2.drop(columns=['target'])\n",
    "    test = test.drop(columns=['target'])\n",
    "    tes2 = test2[col].value_counts()\n",
    "    tes1 = test[col].value_counts()\n",
    "    result = (tes2 / tes1)\n",
    "    for i in range(60):\n",
    "        if i in result.keys():\n",
    "            df.loc[df[col] == i, col] = result[i] ** 2\n",
    "            dft.loc[dft[col] == i, col] = result[i] ** 2\n",
    "        else:\n",
    "            df.loc[df[col] == i, col] = result.mean() ** 2\n",
    "            dft.loc[dft[col] == i, col] = result.mean() ** 2\n",
    "    \n",
    "    \n",
    "scaler = StandardScaler()\n",
    "df[df.columns[:].tolist()] = scaler.fit_transform(df[df.columns[:].tolist()])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dft[dft.columns[:].tolist()] = scaler.fit_transform(dft[dft.columns[:].tolist()])\n",
    "\n",
    "\n",
    "#X = df[df.columns[:].tolist()]\n",
    "#y_train = y\n",
    "#X_train = X.head(64667)\n",
    "#X_test = X.tail(16000)\n",
    "\n",
    "X_train = df[df.columns[:].tolist()]\n",
    "y_train = y\n",
    "X_test = dft[dft.columns[:].tolist()]\n",
    "print(X_test.shape)\n",
    "\n",
    "def modelfit(alg, X, y,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X.values, label=y.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval = 500)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print(cvresult.shape[0])\n",
    "        n_estimators_optimal = cvresult.shape[0]\n",
    "\n",
    "    alg.fit(X, y,eval_metric='auc')\n",
    "\n",
    "    dtrain_predictions = alg.predict(X)\n",
    "    dtrain_predprob = alg.predict_proba(X)[:,1]\n",
    "\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, dtrain_predprob))\n",
    "\n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "\n",
    "alg = XGBClassifier(learning_rate=0.1, n_estimators=205, max_depth=5,\n",
    "                        min_child_weight=3, gamma=0.2, subsample=0.8, colsample_bytree=0.6,\n",
    "\n",
    "                        objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "alg.fit(X_train, y_train)\n",
    "pred_prob = 0.65*alg.predict_proba(X_test)[: ,1]\n",
    "pred_prob2 = 0.35*pred_test\n",
    "total_pred = pred_prob + pred_prob2[0]\n",
    "with open('output3_30.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id,target'])\n",
    "    for i in range(len(total_pred)):\n",
    "        writer.writerow([str(i) + ',' + str(total_pred[i])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
